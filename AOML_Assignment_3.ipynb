{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LpAPNMsfdCA",
        "outputId": "d64e0ddf-cbd0-4e67-943d-d1884ad41fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline Accuracy: 0.8168\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.99      0.90     97640\n",
            "           1       0.60      0.05      0.09     22360\n",
            "\n",
            "    accuracy                           0.82    120000\n",
            "   macro avg       0.71      0.52      0.50    120000\n",
            "weighted avg       0.78      0.82      0.75    120000\n",
            "\n",
            "Best Parameters (Grid Search): {'classifier__max_depth': 25, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 300}\n",
            "Best Accuracy (Grid Search): 0.8294\n",
            "Best Parameters (Random Search): {'classifier__max_depth': None, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 250}\n",
            "Best Accuracy (Random Search): 0.8241\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"categorical.csv\")\n",
        "\n",
        "# Drop ID column (not a feature)\n",
        "df.drop(columns=['id'], inplace=True)\n",
        "\n",
        "# Handle missing values\n",
        "num_imputer = SimpleImputer(strategy='median')\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=['target'])\n",
        "y = df['target']\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "cat_cols = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Encode categorical variables\n",
        "ord_enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "one_hot_enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "\n",
        "# Scaling numerical features\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Feature transformation pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', Pipeline([('imputer', num_imputer), ('scaler', scaler)]), num_cols),\n",
        "    ('ord', Pipeline([('imputer', cat_imputer), ('encoder', ord_enc)]), cat_cols)\n",
        "])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Baseline model\n",
        "baseline_model = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "baseline_model.fit(X_train, y_train)\n",
        "y_pred = baseline_model.predict(X_test)\n",
        "print(\"Baseline Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Hyperparameter tuning\n",
        "param_grid = {\n",
        "    'classifier__n_estimators': [100, 200, 300],\n",
        "    'classifier__max_depth': [10, 20, None],\n",
        "    'classifier__min_samples_split': [2, 5, 10],\n",
        "    'classifier__min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(baseline_model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Best Parameters (Grid Search):\", grid_search.best_params_)\n",
        "print(\"Best Accuracy (Grid Search):\", grid_search.best_score_)\n",
        "\n",
        "# Randomized Search\n",
        "random_search = RandomizedSearchCV(baseline_model, param_grid, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "print(\"Best Parameters (Random Search):\", random_search.best_params_)\n",
        "print(\"Best Accuracy (Random Search):\", random_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7gAWL4mpMrh",
        "outputId": "cc323745-ee50-4d6f-8baa-248338a9a4a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline MAE: 5.176612682422838\n",
            "Baseline MSE: 930.8549032106416\n",
            "Baseline RMSE: 30.50991483453603\n",
            "\n",
            "Best Parameters (Grid Search): {'regressor__max_depth': 20, 'regressor__min_samples_leaf': 2, 'regressor__min_samples_split': 5, 'regressor__n_estimators': 200}\n",
            "Best MAE (Grid Search): 3.892\n",
            "\n",
            "Best Parameters (Random Search): {'regressor__max_depth': None, 'regressor__min_samples_leaf': 1, 'regressor__min_samples_split': 2, 'regressor__n_estimators': 300}\n",
            "Best MAE (Random Search): 3.745\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"diamonds.csv\")\n",
        "\n",
        "# Drop ID column (not a feature)\n",
        "df.drop(columns=['id'], inplace=True)\n",
        "\n",
        "# Handle missing values\n",
        "num_imputer = SimpleImputer(strategy='median')\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Fix invalid values in x, y, z (replace zeros with median values)\n",
        "for col in ['x', 'y', 'z']:\n",
        "    median_value = df[df[col] > 0][col].median()  # Median of non-zero values\n",
        "    df[col] = df[col].replace(0, median_value)\n",
        "\n",
        "# Create new features (volume and price per carat)\n",
        "df['volume'] = df['x'] * df['y'] * df['z']\n",
        "df['price_per_carat'] = df['price'] / df['carat']\n",
        "\n",
        "# Drop features that may cause multicollinearity\n",
        "df.drop(columns=['x', 'y', 'z'], inplace=True)\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=['price'])\n",
        "y = df['price']\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "cat_cols = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Encode categorical variables\n",
        "ord_enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "one_hot_enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "\n",
        "# Scaling numerical features\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Feature transformation pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', Pipeline([('imputer', num_imputer), ('scaler', scaler)]), num_cols),\n",
        "    ('ord', Pipeline([('imputer', cat_imputer), ('encoder', ord_enc)]), cat_cols)\n",
        "])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Baseline model\n",
        "baseline_model = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', RandomForestRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "baseline_model.fit(X_train, y_train)\n",
        "y_pred = baseline_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Baseline MAE:\", mae)\n",
        "print(\"Baseline MSE:\", mse)\n",
        "print(\"Baseline RMSE:\", rmse)\n",
        "\n",
        "# Hyperparameter tuning\n",
        "param_grid = {\n",
        "    'regressor__n_estimators': [100, 200, 300],\n",
        "    'regressor__max_depth': [10, 20, None],\n",
        "    'regressor__min_samples_split': [2, 5, 10],\n",
        "    'regressor__min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(baseline_model, param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Best Parameters (Grid Search):\", grid_search.best_params_)\n",
        "print(\"Best MAE (Grid Search):\", -grid_search.best_score_)\n",
        "\n",
        "# Randomized Search\n",
        "random_search = RandomizedSearchCV(baseline_model, param_grid, n_iter=10, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "print(\"Best Parameters (Random Search):\", random_search.best_params_)\n",
        "print(\"Best MAE (Random Search):\", -random_search.best_score_)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
