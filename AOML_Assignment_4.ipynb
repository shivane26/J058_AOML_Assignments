{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.ensemble import StackingRegressor, VotingRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "train_df.drop(columns=['uid'], errors='ignore', inplace=True)\n",
        "test_df.drop(columns=['uid'], errors='ignore', inplace=True)\n",
        "\n",
        "train_df = pd.get_dummies(train_df, columns=['day'], dummy_na=True)\n",
        "test_df = pd.get_dummies(test_df, columns=['day'], dummy_na=True)\n",
        "\n",
        "X_train = train_df.drop(columns=['output_electricity_generation'], errors='ignore')\n",
        "y_train = train_df['output_electricity_generation']\n",
        "X_test = test_df.copy()\n",
        "\n",
        "for col in set(X_train.columns) - set(X_test.columns):\n",
        "    X_test[col] = 0\n",
        "X_test = X_test[X_train.columns]\n",
        "\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
        "X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
        "\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "lgb_model = lgb.LGBMRegressor(n_estimators=1000, learning_rate=0.03, max_depth=7, subsample=0.8, colsample_bytree=0.8, random_state=42)\n",
        "xgb_model = xgb.XGBRegressor(n_estimators=1000, learning_rate=0.03, max_depth=7, subsample=0.8, colsample_bytree=0.8, random_state=42, tree_method='hist')\n",
        "cat_model = CatBoostRegressor(n_estimators=1000, learning_rate=0.03, depth=7, random_state=42, verbose=0)\n",
        "rf_model = RandomForestRegressor(n_estimators=500, max_depth=10, random_state=42)\n",
        "ext_model = ExtraTreesRegressor(n_estimators=500, max_depth=10, random_state=42)\n",
        "\n",
        "meta_learner = Ridge(alpha=1.0)\n",
        "\n",
        "stacked_model = StackingRegressor(\n",
        "    estimators=[('lgb', lgb_model), ('xgb', xgb_model), ('cat', cat_model), ('rf', rf_model), ('ext', ext_model)],\n",
        "    final_estimator=meta_learner, n_jobs=-1\n",
        ")\n",
        "\n",
        "voting_model = VotingRegressor([('lgb', lgb_model), ('xgb', xgb_model), ('cat', cat_model), ('rf', rf_model), ('ext', ext_model)])\n",
        "\n",
        "rmse_scores = {}\n",
        "\n",
        "for model, name in zip([stacked_model, voting_model], [\"Stacking\", \"Voting\"]):\n",
        "    model.fit(X_train_split, y_train_split)\n",
        "    y_pred = model.predict(X_val)\n",
        "    rmse_scores[name] = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "    print(f\"{name} RMSE: {rmse_scores[name]}\")\n",
        "\n",
        "base_models = [lgb_model, xgb_model, cat_model, rf_model, ext_model]\n",
        "for base in base_models:\n",
        "    base.fit(X_train_split, y_train_split)\n",
        "y_train_blend = np.column_stack([model.predict(X_val) for model in base_models])\n",
        "meta_learner.fit(y_train_blend, y_val)\n",
        "y_pred_blend = meta_learner.predict(y_train_blend)\n",
        "rmse_scores[\"Blending\"] = np.sqrt(mean_squared_error(y_val, y_pred_blend))\n",
        "print(f\"Blending RMSE: {rmse_scores['Blending']}\")\n",
        "\n",
        "best_model = min(rmse_scores, key=rmse_scores.get)\n",
        "print(f\"Best Model: {best_model} with RMSE: {rmse_scores[best_model]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oSq-k_0uVAG",
        "outputId": "c60e45e0-b2ee-48fd-ccfb-89b6538a1c6b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking RMSE: 4.172440638526773\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003279 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2385\n",
            "[LightGBM] [Info] Number of data points in the train set: 40320, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 832.300201\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Voting RMSE: 3.713324832023432\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003174 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2385\n",
            "[LightGBM] [Info] Number of data points in the train set: 40320, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 832.300201\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Blending RMSE: 3.0553029782303596\n",
            "Best Model: Blending with RMSE: 3.0553029782303596\n"
          ]
        }
      ]
    }
  ]
}