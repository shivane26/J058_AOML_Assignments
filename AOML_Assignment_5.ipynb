{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d2eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f181a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "210d975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "data = data[['v1', 'v2']]\n",
    "data.columns = ['label', 'text']\n",
    "data['label'] = data['label'].map({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e70a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f'[{string.punctuation}]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "data['clean_text'] = data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70bde433",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data['text'], data['label'], test_size=0.2, random_state=42\n",
    ")\n",
    "X_train_clean, X_test_clean = data['clean_text'][X_train.index], data['clean_text'][X_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4b18567",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = {\n",
    "    'BOW': CountVectorizer(),\n",
    "    'TF-IDF': TfidfVectorizer()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b21340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train, X_test, y_train, y_test, vectorizer):\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    models = {\n",
    "        'Naive Bayes': MultinomialNB(),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    }\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_vec, y_train)\n",
    "        y_pred = model.predict(X_test_vec)\n",
    "        print(f'\\n=== {name} Model ({vectorizer.__class__.__name__}) ===')\n",
    "        print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "        print('-' * 50)\n",
    "\n",
    "    ensemble = VotingClassifier(estimators=[\n",
    "        ('nb', models['Naive Bayes']),\n",
    "        ('rf', models['Random Forest']),\n",
    "        ('xgb', models['XGBoost'])\n",
    "    ], voting='hard')\n",
    "\n",
    "    ensemble.fit(X_train_vec, y_train)\n",
    "    y_pred = ensemble.predict(X_test_vec)\n",
    "    \n",
    "    print(f'\\n=== Ensemble Model ({vectorizer.__class__.__name__}) ===')\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4695c3a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "##### Training with BOW Features (Raw Text) #####\n",
      "\n",
      "=== Naive Bayes Model (CountVectorizer) ===\n",
      "Accuracy: 0.9839\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       0.99      0.89      0.94       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.95      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Random Forest Model (CountVectorizer) ===\n",
      "Accuracy: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       965\n",
      "           1       1.00      0.82      0.90       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.91      0.94      1115\n",
      "weighted avg       0.98      0.98      0.97      1115\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=== XGBoost Model (CountVectorizer) ===\n",
      "Accuracy: 0.9776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       965\n",
      "           1       0.96      0.87      0.91       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.93      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shiva/Documents/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:50:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/shiva/Documents/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:50:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ensemble Model (CountVectorizer) ===\n",
      "Accuracy: 0.9830\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       1.00      0.87      0.93       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.94      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "##### Training with BOW Features (Cleaned Text) #####\n",
      "\n",
      "=== Naive Bayes Model (CountVectorizer) ===\n",
      "Accuracy: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       965\n",
      "           1       0.96      0.88      0.92       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.94      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Random Forest Model (CountVectorizer) ===\n",
      "Accuracy: 0.9686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       965\n",
      "           1       1.00      0.77      0.87       150\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.88      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=== XGBoost Model (CountVectorizer) ===\n",
      "Accuracy: 0.9776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       0.97      0.86      0.91       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.93      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shiva/Documents/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:50:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/shiva/Documents/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:50:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ensemble Model (CountVectorizer) ===\n",
      "Accuracy: 0.9785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       1.00      0.84      0.91       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.92      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "##### Training with TF-IDF Features (Raw Text) #####\n",
      "\n",
      "=== Naive Bayes Model (TfidfVectorizer) ===\n",
      "Accuracy: 0.9623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       965\n",
      "           1       1.00      0.72      0.84       150\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.98      0.86      0.91      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Random Forest Model (TfidfVectorizer) ===\n",
      "Accuracy: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       965\n",
      "           1       0.99      0.82      0.90       150\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.91      0.94      1115\n",
      "weighted avg       0.98      0.97      0.97      1115\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shiva/Documents/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBoost Model (TfidfVectorizer) ===\n",
      "Accuracy: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       0.98      0.84      0.91       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.92      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shiva/Documents/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:50:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ensemble Model (TfidfVectorizer) ===\n",
      "Accuracy: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       965\n",
      "           1       0.99      0.82      0.90       150\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.91      0.94      1115\n",
      "weighted avg       0.98      0.97      0.97      1115\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "##### Training with TF-IDF Features (Cleaned Text) #####\n",
      "\n",
      "=== Naive Bayes Model (TfidfVectorizer) ===\n",
      "Accuracy: 0.9516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       965\n",
      "           1       1.00      0.64      0.78       150\n",
      "\n",
      "    accuracy                           0.95      1115\n",
      "   macro avg       0.97      0.82      0.88      1115\n",
      "weighted avg       0.95      0.95      0.95      1115\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Random Forest Model (TfidfVectorizer) ===\n",
      "Accuracy: 0.9677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       965\n",
      "           1       1.00      0.76      0.86       150\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.88      0.92      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shiva/Documents/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:50:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBoost Model (TfidfVectorizer) ===\n",
      "Accuracy: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       0.97      0.87      0.92       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.93      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shiva/Documents/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:50:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ensemble Model (TfidfVectorizer) ===\n",
      "Accuracy: 0.9695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       965\n",
      "           1       1.00      0.77      0.87       150\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.89      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for name, vectorizer in vectorizers.items():\n",
    "    print(f'\\n\\n##### Training with {name} Features (Raw Text) #####')\n",
    "    train_models(X_train, X_test, y_train, y_test, vectorizer)\n",
    "    \n",
    "    print(f'\\n\\n##### Training with {name} Features (Cleaned Text) #####')\n",
    "    train_models(X_train_clean, X_test_clean, y_train, y_test, vectorizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
